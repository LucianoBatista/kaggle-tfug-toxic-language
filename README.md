# Classificação de comentários tóxicos

Esse é um repositório que contém alguns experimentos que foram realizados para [classificar comentários tóxicos da competição do Kaggle](https://www.kaggle.com/competitions/ml-olympiad-toxic-language-ptbr-detection/overview).

A explicação de cada experimento está no arquivo `experiments.md`. E os scripts estão no diretório `src`.

Só consegui participar mais pro final da competição, então as estratégias estão bem simples. Mas podem ajudar alguém que está buscando um ponto de partida.
